{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4110c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e9005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading input files\n",
    "titanic_data = pd.read_csv('TITANIC.csv',encoding='ISO-8859â€“1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e7b53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding missing values and their count\n",
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea8d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating function to replace missing ages by median of ages\n",
    "def imput_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    if pd.isnull(Age):\n",
    "        return int(titanic_data[titanic_data[\"Pclass\"] == Pclass][\"Age\"].median())\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7f878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing median age in place of missing values\n",
    "titanic_data[\"Age\"] = titanic_data[[\"Age\", \"Pclass\"]].apply(imput_age, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681bedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping cabin column\n",
    "titanic_data.drop(titanic_data.columns[[10]],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482c4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute embark with the most common value found by visual analysis\n",
    "most_common_value= 'S'\n",
    "\n",
    "for data in titanic_data:\n",
    "    titanic_data['Embarked'] = titanic_data['Embarked'].fillna(most_common_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874a7bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d54e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical features into dummy variables\n",
    "sex = pd.get_dummies(titanic_data['Sex'], drop_first = True)\n",
    "embark = pd.get_dummies(titanic_data['Embarked'], drop_first = True)\n",
    "pclass = pd.get_dummies(titanic_data['Pclass'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ad402f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.drop(['PassengerId', 'Sex', 'Embarked', 'Name', 'Ticket', 'Pclass'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e71c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare\n",
       "0         0  22.0      1      0   7.2500\n",
       "1         1  38.0      1      0  71.2833\n",
       "2         1  26.0      0      0   7.9250\n",
       "3         1  35.0      1      0  53.1000\n",
       "4         0  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "408b425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the dummy variables to the dataset\n",
    "titanic_data = pd.concat([titanic_data, sex, embark, pclass], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc182c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into train and split\n",
    "\n",
    "#shuffling the dataset for random values\n",
    "shuffle_df = titanic_data.sample(frac=1)\n",
    "\n",
    "#defining a size for the train set \n",
    "train_size = int(0.70 * len(titanic_data))\n",
    "\n",
    "#splitting\n",
    "train_set = shuffle_df[:train_size]\n",
    "test_set = shuffle_df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63d5d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate independent [features] and dependent [target] variables\n",
    "x = titanic_data.drop('Survived', axis = 1)\n",
    "y = titanic_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10a85538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining sigmoid and loss functions [y_hat is the prediction]\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1 + np.exp(-z))\n",
    "\n",
    "def loss(y, y_hat):\n",
    "    loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat))\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25eec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "def gradients(x, y, y_hat):\n",
    "    \n",
    "    #m - number of training examples.\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    #gradient of loss w.r.t weights.\n",
    "    dw = (1/m)*np.dot(x.T, (y_hat - y))\n",
    "    \n",
    "    # Gradient of loss w.r.t bias.\n",
    "    db = (1/m)*np.sum((y_hat - y)) \n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5791e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to plot decision boundary (for non-linearly separeable data)\n",
    "def plot_decision_boundary(X, w, b):\n",
    "    \n",
    "    x1 = [min(x[:,0]), max(x[:,0])]\n",
    "    m = -w[0]/w[1]\n",
    "    c = -b/w[1]\n",
    "    x2 = m*x1 + c\n",
    "    \n",
    "    #plotting\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"g^\")\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\")\n",
    "    plt.xlim([-2, 2])\n",
    "    plt.ylim([0, 2.2])\n",
    "    plt.xlabel(\"feature 1\")\n",
    "    plt.ylabel(\"feature 2\")\n",
    "    plt.title('Decision Boundary')\n",
    "    plt.plot(x1, x2, 'y-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74869727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further normalization of input to fit for logistic regression\n",
    "def normalize(x):\n",
    "    \n",
    "    # m - number of training examples\n",
    "    # n - number of features \n",
    "    m, n = x.shape\n",
    "    \n",
    "    for i in range(n):\n",
    "        x = (x - x.mean(axis=0))/x.std(axis=0)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279fd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the train function with initilaizing weights and bias\n",
    "def train(x, y, bs, epochs, lr):\n",
    "    \n",
    "    \n",
    "    #bs - gradient descent batch size\n",
    "    #epochs - number of iterations\n",
    "    #lr - learning rate\n",
    "        \n",
    "    #m - number of training examples\n",
    "    #n - number of features \n",
    "    m, n = x.shape\n",
    "    \n",
    "    #initializing weights and bias to zeros\n",
    "    w = np.zeros((n,1))\n",
    "    b = 0\n",
    "    \n",
    "    #reshaping y\n",
    "    y = y.values.reshape(m,1)\n",
    "    \n",
    "    #normalizing the inputs\n",
    "    x = normalize(x)\n",
    "    \n",
    "    #empty list to store losses\n",
    "    losses = []\n",
    "    \n",
    "    #Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((m-1)//bs + 1):\n",
    "            \n",
    "            # Defining batches. SGD.\n",
    "            start_i = i*bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x[start_i:end_i]\n",
    "            yb = y[start_i:end_i]\n",
    "            \n",
    "            # Calculating prediction.\n",
    "            y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "            \n",
    "            # Getting the gradients of loss w.r.t parameters\n",
    "            dw, db = gradients(xb, yb, y_hat)\n",
    "            \n",
    "            # Updating the parameters.\n",
    "            w -= lr*dw\n",
    "            b -= lr*db\n",
    "        \n",
    "        #appending losses in the lis\n",
    "        y_hat = sigmoid(np.dot(x, w) + b)\n",
    "        l = loss(y, y_hat)\n",
    "        losses.append(l)\n",
    "        \n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f518dc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function\n",
    "def predict(x):\n",
    "    \n",
    "    # Normalizing the inputs.\n",
    "    x = normalize(x)\n",
    "    \n",
    "    # Calculating predictions/y_hat.\n",
    "    preds = sigmoid(np.dot(x, w) + b)\n",
    "    \n",
    "    # Empty List to store predictions.\n",
    "    pred_class = []    \n",
    "    # if y_hat >= 0.5 --> round up to 1\n",
    "    # if y_hat < 0.5 --> round up to 1\n",
    "    pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "    \n",
    "    return np.array(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59cb1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training \n",
    "\n",
    "w, b, l = train(x, y, bs=100, epochs=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee16470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating accuracy function\n",
    "def accuracy(y, y_hat):\n",
    "    accuracy = np.sum(y == y_hat) / len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b64116c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.92031425364759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, y_hat=predict(x))*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
